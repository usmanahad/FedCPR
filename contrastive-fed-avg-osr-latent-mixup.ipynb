{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-30T09:24:16.489960Z",
     "iopub.status.busy": "2025-12-30T09:24:16.489622Z",
     "iopub.status.idle": "2025-12-30T10:29:18.351601Z",
     "shell.execute_reply": "2025-12-30T10:29:18.350950Z",
     "shell.execute_reply.started": "2025-12-30T09:24:16.489936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import copy\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# %%\n",
    "def set_seed(seed=66):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "CONFIG = {\n",
    "    \"batch_size\": 128,\n",
    "    \"closed_lr\": 0.02,\n",
    "    \"local_epochs\": 5,\n",
    "    \"num_clients\": 5,\n",
    "    \"global_rounds\": 50,\n",
    "    \"known_classes\": 6,\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"lambda_contrastive\": 0.5,\n",
    "    \"lambda_trash\": 1.0,\n",
    "    \"temp\": 0.08\n",
    "}\n",
    "\n",
    "set_seed()\n",
    "print(f\"Running on device: {CONFIG['device']}\")\n",
    "\n",
    "# %%\n",
    "#  [Dataset Logic]\n",
    "class CIFAR10FedOSR(Dataset):\n",
    "    def __init__(self, full_dataset, known_classes, is_open=False):\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "        known_class_set = set(known_classes)\n",
    "        for img, label in full_dataset:\n",
    "            if not is_open:\n",
    "                if label in known_class_set:\n",
    "                    self.data.append(img)\n",
    "                    self.targets.append(known_classes.index(label))\n",
    "            else:\n",
    "                if label not in known_class_set:\n",
    "                    self.data.append(img)\n",
    "                    self.targets.append(len(known_classes))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.targets[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "def get_federated_data(num_clients=5, known_count=6, seed=66):\n",
    "    np.random.seed(seed)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./cifar10-python', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "    testset = torchvision.datasets.CIFAR10(root='./cifar10-python', train=False,\n",
    "                                           download=True, transform=transform)\n",
    "    all_classes = np.arange(10)\n",
    "    np.random.shuffle(all_classes)\n",
    "    known_classes = sorted(all_classes[:known_count].tolist())\n",
    "    indices = np.arange(len(trainset))\n",
    "    np.random.shuffle(indices)\n",
    "    client_indices = np.array_split(indices, num_clients)\n",
    "    loaders = []\n",
    "    for idx_list in client_indices:\n",
    "        subset = Subset(trainset, idx_list)\n",
    "        loaders.append(DataLoader(CIFAR10FedOSR(subset, known_classes), batch_size=CONFIG['batch_size'], shuffle=True))\n",
    "    test_close = DataLoader(CIFAR10FedOSR(testset, known_classes, is_open=False), batch_size=CONFIG['batch_size'])\n",
    "    test_open = DataLoader(CIFAR10FedOSR(testset, known_classes, is_open=True), batch_size=CONFIG['batch_size'])\n",
    "    return loaders, test_close, test_open, known_classes\n",
    "\n",
    "\n",
    "# %%\n",
    "#  [Model: PrototypeCNN (256-dim features)]\n",
    "class PrototypeCNN(nn.Module):\n",
    "    def __init__(self, num_classes=6, input_channels=3):\n",
    "        super(PrototypeCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(256)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(256)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # Anchors for known classes\n",
    "        self.fc = nn.Linear(256, num_classes, bias=False)\n",
    "\n",
    "    def pre2block(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "    def latter_forward(self, x):\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn7(self.conv7(x)))\n",
    "        x = F.relu(self.bn8(self.conv8(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.global_pool(x)\n",
    "        feat = x.view(x.size(0), -1)\n",
    "        return F.normalize(feat, p=2, dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.get_features(x)\n",
    "        logits = self.fc(feat)\n",
    "        return logits, feat\n",
    "\n",
    "    def get_features(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn7(self.conv7(x)))\n",
    "        x = F.relu(self.bn8(self.conv8(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.global_pool(x)\n",
    "        feat = x.view(x.size(0), -1)\n",
    "        return F.normalize(feat, p=2, dim=1)\n",
    "\n",
    "\n",
    "# %%\n",
    "#  [Losses and Helpers]\n",
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        sim = torch.matmul(features, features.T) / self.temperature\n",
    "        labels = labels.contiguous().view(-1, 1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(features.device)\n",
    "        logits_mask = torch.ones_like(mask) - torch.eye(mask.size(0), device=features.device)\n",
    "        mask *= logits_mask\n",
    "        exp_sim = torch.exp(sim) * logits_mask\n",
    "        log_prob = sim - torch.log(exp_sim.sum(dim=1, keepdim=True) + 1e-12)\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / (mask.sum(1) + 1e-12)\n",
    "        return -mean_log_prob_pos.mean()\n",
    "\n",
    "\n",
    "def compute_class_means(model, loader, device, num_classes):\n",
    "    \"\"\"Compute class centroids from training data.\"\"\"\n",
    "    model.eval()\n",
    "    feats, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            _, f = model(x.to(device))\n",
    "            feats.append(f)\n",
    "            labels.append(y)\n",
    "    feats = torch.cat(feats)\n",
    "    labels = torch.cat(labels)\n",
    "    class_means = []\n",
    "    for k in range(num_classes):\n",
    "        class_feats = feats[labels == k]\n",
    "        if len(class_feats) > 0:\n",
    "            class_means.append(F.normalize(class_feats.mean(0), dim=0))\n",
    "        else:\n",
    "            class_means.append(torch.zeros(256).to(device))\n",
    "    return torch.stack(class_means)\n",
    "\n",
    "\n",
    "def calculate_osr_scores(features, centroids, temperature):\n",
    "    \"\"\"\n",
    "    Calculate multiple OSR scores for open-set detection.\n",
    "\n",
    "    Args:\n",
    "        features: (N, D) normalized feature vectors\n",
    "        centroids: (K, D) class centroids/prototypes\n",
    "        temperature: temperature scaling factor\n",
    "\n",
    "    Returns:\n",
    "        scores_min_dist: minimum distance to any centroid (higher = more likely open-set)\n",
    "        scores_energy: negative energy score (higher = more likely open-set)\n",
    "        scores_entropy: entropy of softmax probabilities (higher = more likely open-set)\n",
    "    \"\"\"\n",
    "    # Compute distances to all centroids\n",
    "    # For normalized vectors, squared L2 distance = 2 - 2*cosine_sim\n",
    "    # Or we can use cosine similarity directly\n",
    "    similarities = torch.matmul(features, centroids.T)  # (N, K)\n",
    "\n",
    "    # 1. Minimum Distance Score (using cosine similarity, so we negate for \"distance\")\n",
    "    # Lower similarity = higher distance = more likely open-set\n",
    "    max_sim, _ = similarities.max(dim=1)\n",
    "    scores_min_dist = (1 - max_sim).cpu().tolist()  # Convert similarity to distance-like score\n",
    "\n",
    "    # 2. Energy Score\n",
    "    # Energy = -T * log(sum(exp(logits/T)))\n",
    "    # Higher energy (less negative) = more uncertain = more likely open-set\n",
    "    logits = similarities / temperature\n",
    "    energy = -temperature * torch.logsumexp(logits, dim=1)\n",
    "    scores_energy = energy.cpu().tolist()  # Higher (less negative) = open-set\n",
    "\n",
    "    # 3. Entropy Score\n",
    "    # Higher entropy = more uniform distribution = more uncertain = more likely open-set\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    entropy = -torch.sum(probs * torch.log(probs + 1e-12), dim=1)\n",
    "    scores_entropy = entropy.cpu().tolist()\n",
    "\n",
    "    return scores_min_dist, scores_energy, scores_entropy\n",
    "\n",
    "\n",
    "def create_curriculum_trash(inputs, progress, device):\n",
    "    trash_imgs = inputs.clone()\n",
    "    batch_size = inputs.size(0)\n",
    "    tier = 1 if progress < 0.2 else (2 if progress < 0.5 else 3)\n",
    "    for i in range(batch_size):\n",
    "        img = trash_imgs[i]\n",
    "        if tier == 1:  # Jigsaw\n",
    "            C, H, W = img.shape\n",
    "            h, w = H // 2, W // 2\n",
    "            q = [img[:, :h, :w], img[:, :h, w:], img[:, h:, :w], img[:, h:, w:]]\n",
    "            random.shuffle(q)\n",
    "            img = torch.cat([torch.cat([q[0], q[1]], 2), torch.cat([q[2], q[3]], 2)], 1)\n",
    "        elif tier == 2:  # 180 Rotation or VFlip\n",
    "            img = transforms.functional.vflip(img) if random.random() < 0.5 else torch.rot90(img, 2, [1, 2])\n",
    "        else:  # 90/270 Rotation\n",
    "            img = torch.rot90(img, random.choice([1, 3]), [1, 2])\n",
    "        trash_imgs[i] = img\n",
    "    return trash_imgs.to(device)\n",
    "\n",
    "\n",
    "def plot_tsne_osr(model, test_cl, test_op, round_idx, device):\n",
    "    model.eval()\n",
    "    projs, labels = [], []\n",
    "\n",
    "    # Define markers for the known classes\n",
    "    marker_list = ['o', 's', '^', 'D', 'P', '*', 'v', 'p', 'h', 'X']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get Projections for Closed-set\n",
    "        for i, (x, y) in enumerate(test_cl):\n",
    "            _, p = model(x.to(device))\n",
    "            projs.append(p.cpu())\n",
    "            labels.extend([f\"Known_{j}\" for j in y.numpy()])\n",
    "            if i > 10:\n",
    "                break\n",
    "\n",
    "        # Get Projections for Open-set\n",
    "        for i, (x, _) in enumerate(test_op):\n",
    "            _, p = model(x.to(device))\n",
    "            projs.append(p.cpu())\n",
    "            labels.extend([\"Unknown\"] * x.size(0))\n",
    "            if i > 10:\n",
    "                break\n",
    "\n",
    "    all_projs = torch.cat(projs).numpy()\n",
    "    labels = np.array(labels)\n",
    "    tsne = TSNE(n_components=2, perplexity=30, random_state=66)\n",
    "    embedded = tsne.fit_transform(all_projs)\n",
    "\n",
    "    # Setup Custom Palette and Markers\n",
    "    unique_labels = sorted(list(set(labels)))\n",
    "    custom_palette = {l: \"blue\" if \"Known\" in l else \"orange\" for l in unique_labels}\n",
    "    known_labels = [l for l in unique_labels if \"Known\" in l]\n",
    "    custom_markers = {l: marker_list[i % len(marker_list)] for i, l in enumerate(known_labels)}\n",
    "    custom_markers[\"Unknown\"] = \"X\"\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.scatterplot(\n",
    "        x=embedded[:, 0],\n",
    "        y=embedded[:, 1],\n",
    "        hue=labels,\n",
    "        style=labels,\n",
    "        palette=custom_palette,\n",
    "        markers=custom_markers,\n",
    "        s=60,\n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "    plt.title(f\"t-SNE of Contrastive Projections - Round {round_idx}\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # plt.savefig(f\"tsne_round_{round_idx}.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# %%\n",
    "#  [Federated Training Logic]\n",
    "def train_client(model, loader, config, current_round, client_idx):\n",
    "    model.train()\n",
    "    supcon_loss_fn = SupConLoss(temperature=config['temp'])\n",
    "    optimizer = optim.SGD(model.parameters(), lr=config[\"closed_lr\"], momentum=0.9, weight_decay=5e-4)\n",
    "    progress = current_round / config['global_rounds']\n",
    "\n",
    "    for epoch in range(config[\"local_epochs\"]):\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(config[\"device\"]), y.to(config[\"device\"])\n",
    "            optimizer.zero_grad()\n",
    "            logits, feat = model(x)\n",
    "\n",
    "            # Known Training\n",
    "            loss_ce = F.cross_entropy(logits, y)\n",
    "            loss_sc = supcon_loss_fn(feat, y)\n",
    "\n",
    "            # Trash Training (Entropic Rejection)\n",
    "            lt = model.pre2block(x)\n",
    "            mx_lt = create_curriculum_trash(lt, progress, config['device'])\n",
    "            trash_feat = model.latter_forward(mx_lt)\n",
    "            # trash_x = create_curriculum_trash(x, progress, config['device'])\n",
    "            # _, trash_feat = model(trash_x)\n",
    "            anchors = F.normalize(model.fc.weight, dim=1)\n",
    "            trash_logits = torch.matmul(trash_feat, anchors.T) / config['temp']\n",
    "            uniform_target = torch.full_like(trash_logits, 1.0 / config['known_classes'])\n",
    "            loss_trash = F.kl_div(F.log_softmax(trash_logits, dim=1), uniform_target, reduction='batchmean')\n",
    "\n",
    "            loss = loss_ce + (config['lambda_contrastive'] * loss_sc) + (config['lambda_trash'] * loss_trash)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def federated_communication_fedavg(server_model, client_models):\n",
    "    new_global = copy.deepcopy(client_models[0].state_dict())\n",
    "    for key in new_global.keys():\n",
    "        for i in range(1, len(client_models)):\n",
    "            new_global[key] += client_models[i].state_dict()[key]\n",
    "        if torch.is_floating_point(new_global[key]):\n",
    "            new_global[key] /= len(client_models)\n",
    "        else:\n",
    "            new_global[key] = torch.div(new_global[key], len(client_models), rounding_mode='floor')\n",
    "    server_model.load_state_dict(new_global)\n",
    "    return server_model\n",
    "\n",
    "\n",
    "# %%\n",
    "loaders, test_cl, test_op, known_list = get_federated_data()\n",
    "print(f\"Known classes: {known_list}\")\n",
    "\n",
    "server_model = PrototypeCNN(num_classes=CONFIG['known_classes']).to(CONFIG['device'])\n",
    "client_models = [copy.deepcopy(server_model) for _ in range(CONFIG['num_clients'])]\n",
    "\n",
    "# Initialize best metrics\n",
    "best_acc = 0\n",
    "best_auc_min = 0\n",
    "best_auc_eng = 0\n",
    "best_auc_ent = 0\n",
    "\n",
    "for r in range(CONFIG['global_rounds']):\n",
    "    print(f\"\\n--- Round {r + 1} ---\")\n",
    "\n",
    "    # Train clients\n",
    "    for i in range(CONFIG['num_clients']):\n",
    "        train_client(client_models[i], loaders[i], CONFIG, r, i + 1)\n",
    "\n",
    "    # Aggregate models\n",
    "    server_model = federated_communication_fedavg(server_model, client_models)\n",
    "    for m in client_models:\n",
    "        m.load_state_dict(server_model.state_dict())\n",
    "\n",
    "    # Evaluation\n",
    "    server_model.eval()\n",
    "    correct, total = 0, 0\n",
    "    labels_binary = []\n",
    "    scores_min, scores_energy, scores_entropy = [], [], []\n",
    "\n",
    "    # Use the FC layer weights as class prototypes/centroids\n",
    "    # These are learned anchors for each known class\n",
    "    with torch.no_grad():\n",
    "        centroids = F.normalize(server_model.fc.weight, dim=1)  # (K, 256)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # --- Known Class Evaluation ---\n",
    "        for x, y in test_cl:\n",
    "            x, y = x.to(CONFIG['device']), y.to(CONFIG['device'])\n",
    "            logits, feat = server_model(x)\n",
    "\n",
    "            # Accuracy (using logits directly or nearest centroid)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += preds.eq(y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "            # OSR Scores (known samples should have LOW scores)\n",
    "            s_min, s_eng, s_ent = calculate_osr_scores(feat, centroids, CONFIG['temp'])\n",
    "            scores_min.extend(s_min)\n",
    "            scores_energy.extend(s_eng)\n",
    "            scores_entropy.extend(s_ent)\n",
    "            labels_binary.extend([0] * x.size(0))  # 0 = known\n",
    "\n",
    "        # --- Open Set Evaluation ---\n",
    "        for x, _ in test_op:\n",
    "            x = x.to(CONFIG['device'])\n",
    "            _, feat = server_model(x)\n",
    "\n",
    "            # OSR Scores (open-set samples should have HIGH scores)\n",
    "            s_min, s_eng, s_ent = calculate_osr_scores(feat, centroids, CONFIG['temp'])\n",
    "            scores_min.extend(s_min)\n",
    "            scores_energy.extend(s_eng)\n",
    "            scores_entropy.extend(s_ent)\n",
    "            labels_binary.extend([1] * x.size(0))  # 1 = unknown/open-set\n",
    "\n",
    "    # --- Metrics ---\n",
    "    acc = 100. * correct / total\n",
    "    auc_min = roc_auc_score(labels_binary, scores_min) * 100\n",
    "    auc_eng = roc_auc_score(labels_binary, scores_energy) * 100\n",
    "    auc_ent = roc_auc_score(labels_binary, scores_entropy) * 100\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "    if auc_min > best_auc_min:\n",
    "        best_auc_min = auc_min\n",
    "    if auc_eng > best_auc_eng:\n",
    "        best_auc_eng = auc_eng\n",
    "    if auc_ent > best_auc_ent:\n",
    "        best_auc_ent = auc_ent\n",
    "\n",
    "    print(f\"[Global Metrics] Acc: {acc:.2f}% (Best: {best_acc:.2f}%)\")\n",
    "    print(f\"AUROC (Min Dist): {auc_min:.2f}% (Best: {best_auc_min:.2f}%)\")\n",
    "    print(f\"AUROC (Energy):   {auc_eng:.2f}% (Best: {best_auc_eng:.2f}%)\")\n",
    "    print(f\"AUROC (Entropy):  {auc_ent:.2f}% (Best: {best_auc_ent:.2f}%)\")\n",
    "\n",
    "    # Visualization every 10 rounds\n",
    "    # if (r + 1) % 10 == 0:\n",
    "    plot_tsne_osr(server_model, test_cl, test_op, r + 1, CONFIG['device'])\n",
    "    # print(f\"Saved t-SNE plot for round {r + 1}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Training Complete!\")\n",
    "print(f\"Best Accuracy: {best_acc:.2f}%\")\n",
    "print(f\"Best AUROC (Min Dist): {best_auc_min:.2f}%\")\n",
    "print(f\"Best AUROC (Energy): {best_auc_eng:.2f}%\")\n",
    "print(f\"Best AUROC (Entropy): {best_auc_ent:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 11102,
     "sourceId": 15444,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31240,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
